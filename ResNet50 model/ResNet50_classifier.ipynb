{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Local Python",
      "language": "python",
      "name": "local"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "crack-detection-resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "VexIBTPcsr43",
        "colab_type": "code",
        "outputId": "4f509880-eafd-4c1e-e101-fa67c799e2dc",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "KKvYlV-ksr5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "eocTc_pXsr5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "SXviRNOGsr5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## get the data\n",
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "scrolled": true,
        "trusted": true,
        "id": "1cng2Rg3sr5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip concrete_data_week3.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "MDuxGCsTsr5x",
        "colab_type": "text"
      },
      "source": [
        "## Define Global Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "6VWE-YTlsr5y",
        "colab_type": "text"
      },
      "source": [
        "Here, we will define constants that we will be using throughout the rest of the lab. \n",
        "\n",
        "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
        "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
        "3. We will training and validating the model using batches of 100 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "C2c2mBb7sr50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 2\n",
        "\n",
        "image_resize = 224\n",
        "\n",
        "batch_size_training = 100\n",
        "batch_size_validation = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "E3xGKYR_sr59",
        "colab_type": "text"
      },
      "source": [
        "## Construct ImageDataGenerator Instances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "PVT9n2Aesr5-",
        "colab_type": "text"
      },
      "source": [
        "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "t5uQVxSwsr5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "U0V0-68Csr6E",
        "colab_type": "text"
      },
      "source": [
        "Next, we will use the *flow_from_directory* method to get the training images as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "MSECrFGAsr6G",
        "colab_type": "code",
        "outputId": "db0d393f-fac6-4795-abcb-a5bf532ec494",
        "colab": {}
      },
      "source": [
        "train_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/train',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_training,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 30001 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "0-9c_78gsr6O",
        "colab_type": "code",
        "outputId": "734e51c1-e4b1-4fe9-b2e7-082dd2e44a39",
        "colab": {}
      },
      "source": [
        "## Type your answer here\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/valid',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_validation,\n",
        "    class_mode='categorical')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10001 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "SQ7iipWUsr6V",
        "colab_type": "text"
      },
      "source": [
        "## Build, Compile and Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "fU5o7JwHsr6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Pj1rTFFJsr6d",
        "colab_type": "text"
      },
      "source": [
        "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "5NGNltJ2sr6e",
        "colab_type": "code",
        "outputId": "75539a61-575a-462d-efdc-f89bb47380fb",
        "colab": {}
      },
      "source": [
        "model.add(ResNet50(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet',\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "LBJE6TCmsr6k",
        "colab_type": "text"
      },
      "source": [
        "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "cyn5kiNysr6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "AdEfGISdsr6q",
        "colab_type": "text"
      },
      "source": [
        "You can access the model's layers using the *layers* attribute of our model object. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "6GtQv9D5sr6q",
        "colab_type": "code",
        "outputId": "ab567d81-3293-40fc-f9b7-55db56446a18",
        "colab": {}
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.training.Model at 0x7f05a83f9780>,\n",
              " <keras.layers.core.Dense at 0x7f05df69a748>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Zs8k3ycRsr6w",
        "colab_type": "text"
      },
      "source": [
        "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "FurBHdNCsr6x",
        "colab_type": "text"
      },
      "source": [
        "You can access the ResNet50 layers by running the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "scrolled": true,
        "trusted": true,
        "id": "ewIuTf2Ysr6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.layers[0].layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "OHGhF6WKsr63",
        "colab_type": "text"
      },
      "source": [
        "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "LBBHNKtOsr64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.layers[0].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "CnZvatSSsr68",
        "colab_type": "text"
      },
      "source": [
        "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "ApUVaUJesr6-",
        "colab_type": "code",
        "outputId": "cd5f3eb0-8103-482c-cf5d-71744825da9c",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 23,591,810\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "rAlS8YT-sr7D",
        "colab_type": "text"
      },
      "source": [
        "Next we compile our model using the **adam** optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "62bZLm90sr7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "1wlI2GfGsr7H",
        "colab_type": "text"
      },
      "source": [
        "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "DQx7UR10sr7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps_per_epoch_training = len(train_generator)\n",
        "steps_per_epoch_validation = len(validation_generator)\n",
        "num_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "fvSIoITSsr7O",
        "colab_type": "text"
      },
      "source": [
        "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "PFUcWaxdsr7P",
        "colab_type": "code",
        "outputId": "a5e191dd-4bb1-43c7-94f3-a75c31cedad1",
        "colab": {}
      },
      "source": [
        "fit_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "301/301 [==============================] - 147s 490ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 0.0246 - val_accuracy: 0.8797\n",
            "Epoch 2/10\n",
            "301/301 [==============================] - 136s 453ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 5.2452e-06 - val_accuracy: 0.9304\n",
            "Epoch 3/10\n",
            "301/301 [==============================] - 135s 449ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 2.1980e-04 - val_accuracy: 0.9303\n",
            "Epoch 4/10\n",
            "301/301 [==============================] - 136s 452ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0130 - val_accuracy: 0.9390\n",
            "Epoch 5/10\n",
            "301/301 [==============================] - 136s 452ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0000e+00 - val_accuracy: 0.9672\n",
            "Epoch 6/10\n",
            "301/301 [==============================] - 137s 454ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 6.7949e-06 - val_accuracy: 0.9653\n",
            "Epoch 7/10\n",
            "301/301 [==============================] - 136s 451ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.5497e-06 - val_accuracy: 0.9589\n",
            "Epoch 8/10\n",
            "301/301 [==============================] - 136s 452ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 0.9664\n",
            "Epoch 9/10\n",
            "301/301 [==============================] - 136s 452ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 2.8511e-04 - val_accuracy: 0.9479\n",
            "Epoch 10/10\n",
            "301/301 [==============================] - 136s 451ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 5.7220e-06 - val_accuracy: 0.9522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "trusted": true,
        "id": "fCxVgx4Tsr7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('classifier_resnet50_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}